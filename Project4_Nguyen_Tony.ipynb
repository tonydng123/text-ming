{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 614 Text Mining\n",
    "# Project 4: The Bag of Words and TF-IDF Model\n",
    "## By Tony Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. The Bag of Words and TF-IDF Model on Movie Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kiya tho refresh maarkefir comment karo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surat women perform yagna seeks divine grace f...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>this comes from cabinet which has scholars lik...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>with upcoming election india saga going import...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gandhi was gay does modi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0\n",
       "5           kiya tho refresh maarkefir comment karo        0.0\n",
       "6  surat women perform yagna seeks divine grace f...       0.0\n",
       "7  this comes from cabinet which has scholars lik...       0.0\n",
       "8  with upcoming election india saga going import...       1.0\n",
       "9                         gandhi was gay does modi         1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "twitter_data = pd.read_csv('./Twitter_Data.csv')\n",
    "twitter_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Convert the column of the clean_text to a matrix of token counts using CountVectorizer and unigrams and bigrams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the feature matrix for the texts = (162980, 106925)\n",
      "The first row of the feature matrix =   (0, 103780)\t1\n",
      "  (0, 62481)\t1\n",
      "  (0, 76937)\t1\n",
      "  (0, 61637)\t1\n",
      "  (0, 40527)\t1\n",
      "  (0, 60317)\t1\n",
      "  (0, 40499)\t1\n",
      "  (0, 34701)\t1\n",
      "  (0, 43980)\t1\n",
      "  (0, 13684)\t1\n",
      "  (0, 95482)\t2\n",
      "  (0, 29341)\t1\n",
      "  (0, 51357)\t1\n",
      "  (0, 80438)\t1\n",
      "  (0, 91104)\t2\n",
      "  (0, 103994)\t1\n",
      "  (0, 30477)\t1\n",
      "  (0, 93828)\t1\n",
      "  (0, 105521)\t1\n",
      "  (0, 39396)\t1\n",
      "  (0, 51985)\t1\n",
      "  (0, 87792)\t2\n",
      "  (0, 8389)\t3\n",
      "  (0, 67998)\t1\n",
      "  (0, 17907)\t1\n",
      "  (0, 34636)\t1\n",
      "  (0, 77543)\t1\n",
      "  (0, 94774)\t1.\n",
      "There are 28/106925 non-zeros\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "# Create a Vectorizer Object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# Learn the vocabulary dictionary and return document-term matrix.\n",
    "matrix = vectorizer.fit_transform(twitter_data['clean_text'].values.astype('U'))\n",
    "  \n",
    "# Summarizing the numerical features from texts\n",
    "print(f'The size of the feature matrix for the texts = {matrix.get_shape()}')\n",
    "print(f'The first row of the feature matrix = {matrix[0, ]}.')\n",
    "print(f'There are {matrix[0, ].count_nonzero()}/{matrix.get_shape()[1]} non-zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the feature matrix for the texts = (162980, 1199726)\n",
      "The first row of the feature matrix =   (0, 1145440)\t1\n",
      "  (0, 666553)\t1\n",
      "  (0, 831879)\t1\n",
      "  (0, 658439)\t1\n",
      "  (0, 435499)\t1\n",
      "  (0, 644088)\t1\n",
      "  (0, 435147)\t1\n",
      "  (0, 357405)\t1\n",
      "  (0, 480830)\t1\n",
      "  (0, 134189)\t1\n",
      "  (0, 1029272)\t2\n",
      "  (0, 299531)\t1\n",
      "  (0, 554530)\t1\n",
      "  (0, 867040)\t1\n",
      "  (0, 976966)\t2\n",
      "  (0, 1155022)\t1\n",
      "  (0, 308537)\t1\n",
      "  (0, 1006650)\t1\n",
      "  (0, 1183134)\t1\n",
      "  (0, 419834)\t1\n",
      "  (0, 562994)\t1\n",
      "  (0, 940186)\t2\n",
      "  (0, 66073)\t3\n",
      "  (0, 728515)\t1\n",
      "  (0, 175799)\t1\n",
      "  :\t:\n",
      "  (0, 357481)\t1\n",
      "  (0, 481028)\t1\n",
      "  (0, 134240)\t1\n",
      "  (0, 1032237)\t1\n",
      "  (0, 299593)\t1\n",
      "  (0, 555045)\t1\n",
      "  (0, 867045)\t1\n",
      "  (0, 1038737)\t1\n",
      "  (0, 977642)\t1\n",
      "  (0, 1155443)\t1\n",
      "  (0, 309052)\t1\n",
      "  (0, 1007448)\t1\n",
      "  (0, 1183662)\t1\n",
      "  (0, 420543)\t1\n",
      "  (0, 563133)\t1\n",
      "  (0, 977518)\t1\n",
      "  (0, 940260)\t1\n",
      "  (0, 72487)\t1\n",
      "  (0, 729194)\t1\n",
      "  (0, 175815)\t1\n",
      "  (0, 74556)\t1\n",
      "  (0, 940632)\t1\n",
      "  (0, 356855)\t1\n",
      "  (0, 838915)\t1\n",
      "  (0, 75386)\t1.\n",
      "There are 60/1199726 non-zeros\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create a Vectorizer Object using 1-grams and 2-grams\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# Encode the corpus\n",
    "# Extract token counts out of raw text documents using the vocabulary\n",
    "matrix = vectorizer.fit_transform(twitter_data['clean_text'].values.astype('U'))\n",
    "  \n",
    "# Summarizing the numerical features from texts\n",
    "print(f'The size of the feature matrix for the texts = {matrix.get_shape()}')\n",
    "print(f'The first row of the feature matrix = {matrix[0, ]}.')\n",
    "print(f'There are {matrix[0, ].count_nonzero()}/{matrix.get_shape()[1]} non-zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Perform the tf-idf analasys on the column of the clean_text using CountVectorizer and TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the count matrix for the texts = (162980, 106925)\n",
      "The sparse count matrix is as follows:\n",
      "  (0, 103780)\t1\n",
      "  (0, 62481)\t1\n",
      "  (0, 76937)\t1\n",
      "  (0, 61637)\t1\n",
      "  (0, 40527)\t1\n",
      "  (0, 60317)\t1\n",
      "  (0, 40499)\t1\n",
      "  (0, 34701)\t1\n",
      "  (0, 43980)\t1\n",
      "  (0, 13684)\t1\n",
      "  (0, 95482)\t2\n",
      "  (0, 29341)\t1\n",
      "  (0, 51357)\t1\n",
      "  (0, 80438)\t1\n",
      "  (0, 91104)\t2\n",
      "  (0, 103994)\t1\n",
      "  (0, 30477)\t1\n",
      "  (0, 93828)\t1\n",
      "  (0, 105521)\t1\n",
      "  (0, 39396)\t1\n",
      "  (0, 51985)\t1\n",
      "  (0, 87792)\t2\n",
      "  (0, 8389)\t3\n",
      "  (0, 67998)\t1\n",
      "  (0, 17907)\t1\n",
      "  :\t:\n",
      "  (162979, 65873)\t1\n",
      "  (162979, 56603)\t1\n",
      "  (162979, 95375)\t1\n",
      "  (162979, 63947)\t1\n",
      "  (162979, 5841)\t1\n",
      "  (162979, 5191)\t1\n",
      "  (162979, 74812)\t1\n",
      "  (162979, 17962)\t1\n",
      "  (162979, 69383)\t1\n",
      "  (162979, 43151)\t1\n",
      "  (162979, 103788)\t1\n",
      "  (162979, 47231)\t1\n",
      "  (162979, 82981)\t2\n",
      "  (162979, 34101)\t1\n",
      "  (162979, 34124)\t1\n",
      "  (162979, 89693)\t1\n",
      "  (162979, 77339)\t1\n",
      "  (162979, 10864)\t2\n",
      "  (162979, 44215)\t1\n",
      "  (162979, 25873)\t1\n",
      "  (162979, 56816)\t1\n",
      "  (162979, 58707)\t1\n",
      "  (162979, 29767)\t1\n",
      "  (162979, 58706)\t1\n",
      "  (162979, 41683)\t1\n",
      "The size of the tf_idf matrix for the texts = (162980, 106925)\n",
      "The sparse tf_idf matrix is as follows:\n",
      "  (0, 105521)\t0.12028353756840601\n",
      "  (0, 103994)\t0.10858429770134567\n",
      "  (0, 103780)\t0.11668604692600501\n",
      "  (0, 95482)\t0.1103369330198538\n",
      "  (0, 94774)\t0.23660466349027023\n",
      "  (0, 93828)\t0.13399957155223954\n",
      "  (0, 91104)\t0.3105076608504044\n",
      "  (0, 87792)\t0.2387429732629813\n",
      "  (0, 80438)\t0.3147731549491533\n",
      "  (0, 77543)\t0.2644440348083726\n",
      "  (0, 76937)\t0.1661604402232868\n",
      "  (0, 67998)\t0.08143445561404204\n",
      "  (0, 62481)\t0.03336926835844093\n",
      "  (0, 61637)\t0.1889103368727531\n",
      "  (0, 60317)\t0.21686927892530608\n",
      "  (0, 51985)\t0.2030659320709923\n",
      "  (0, 51357)\t0.15495537757250963\n",
      "  (0, 43980)\t0.11613399134304461\n",
      "  (0, 40527)\t0.12554675089481607\n",
      "  (0, 40499)\t0.1921722923035772\n",
      "  (0, 39396)\t0.12597803421480075\n",
      "  (0, 34701)\t0.20196161088022185\n",
      "  (0, 34636)\t0.2517650765565202\n",
      "  (0, 30477)\t0.1452398919187344\n",
      "  (0, 29341)\t0.20379916078250251\n",
      "  :\t:\n",
      "  (162979, 82981)\t0.3425153753558636\n",
      "  (162979, 77339)\t0.1506084640568452\n",
      "  (162979, 74812)\t0.15343395605175814\n",
      "  (162979, 69383)\t0.10561082092724194\n",
      "  (162979, 65873)\t0.10545092368402072\n",
      "  (162979, 63947)\t0.11821826302011917\n",
      "  (162979, 62481)\t0.03354737635251277\n",
      "  (162979, 58707)\t0.2720687795854384\n",
      "  (162979, 58706)\t0.2631908704622822\n",
      "  (162979, 56816)\t0.18852675243683265\n",
      "  (162979, 56603)\t0.10462706020729619\n",
      "  (162979, 47231)\t0.12161833615006477\n",
      "  (162979, 44215)\t0.22911244118600838\n",
      "  (162979, 43151)\t0.0922201690943638\n",
      "  (162979, 41683)\t0.3407064002583396\n",
      "  (162979, 37266)\t0.06756510559574486\n",
      "  (162979, 34124)\t0.1607220383084633\n",
      "  (162979, 34101)\t0.12109384868662275\n",
      "  (162979, 29767)\t0.25797207796634797\n",
      "  (162979, 25873)\t0.20296190068031533\n",
      "  (162979, 17962)\t0.0930068253672693\n",
      "  (162979, 10864)\t0.3364426864094962\n",
      "  (162979, 9779)\t0.08443245150365022\n",
      "  (162979, 5841)\t0.1755040283953335\n",
      "  (162979, 5191)\t0.11241623159748944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Create a Vectorizer Object using default parameters\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# Extract token counts out of raw text documents using the vocabulary\n",
    "token_count_matrix=vectorizer.fit_transform(twitter_data['clean_text'].values.astype('U'))\n",
    "print(f'The size of the count matrix for the texts = {token_count_matrix.get_shape()}')\n",
    "print(f'The sparse count matrix is as follows:')\n",
    "print(token_count_matrix)\n",
    "\n",
    "# Create a tf_idf object using default parameters\n",
    "tf_idf_transformer=TfidfTransformer(use_idf=True, smooth_idf=True, sublinear_tf=False) \n",
    "\n",
    "# Fit to the count matrix, then transform it to a normalized tf-idf representation\n",
    "tf_idf_matrix = tf_idf_transformer.fit_transform(token_count_matrix)\n",
    "\n",
    "print(f'The size of the tf_idf matrix for the texts = {tf_idf_matrix.get_shape()}')\n",
    "print(f'The sparse tf_idf matrix is as follows:')\n",
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Perform the tf-idf analysis on the column of the clean_text using Tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the tf_idf matrix for the texts = (162980, 106925)\n",
      "The sparse tf_idf matrix is as follows:\n",
      "  (0, 94774)\t0.23660466349027023\n",
      "  (0, 77543)\t0.2644440348083726\n",
      "  (0, 34636)\t0.2517650765565202\n",
      "  (0, 17907)\t0.18097741396817904\n",
      "  (0, 67998)\t0.08143445561404204\n",
      "  (0, 8389)\t0.1858717788592678\n",
      "  (0, 87792)\t0.2387429732629813\n",
      "  (0, 51985)\t0.2030659320709923\n",
      "  (0, 39396)\t0.12597803421480075\n",
      "  (0, 105521)\t0.12028353756840601\n",
      "  (0, 93828)\t0.13399957155223954\n",
      "  (0, 30477)\t0.1452398919187344\n",
      "  (0, 103994)\t0.10858429770134567\n",
      "  (0, 91104)\t0.3105076608504044\n",
      "  (0, 80438)\t0.3147731549491533\n",
      "  (0, 51357)\t0.15495537757250963\n",
      "  (0, 29341)\t0.20379916078250251\n",
      "  (0, 95482)\t0.1103369330198538\n",
      "  (0, 13684)\t0.2282834313221842\n",
      "  (0, 43980)\t0.11613399134304461\n",
      "  (0, 34701)\t0.20196161088022185\n",
      "  (0, 40499)\t0.1921722923035772\n",
      "  (0, 60317)\t0.21686927892530608\n",
      "  (0, 40527)\t0.12554675089481607\n",
      "  (0, 61637)\t0.1889103368727531\n",
      "  :\t:\n",
      "  (162979, 10864)\t0.3364426864094962\n",
      "  (162979, 77339)\t0.1506084640568452\n",
      "  (162979, 89693)\t0.1773137606663935\n",
      "  (162979, 34124)\t0.1607220383084633\n",
      "  (162979, 34101)\t0.12109384868662275\n",
      "  (162979, 82981)\t0.3425153753558636\n",
      "  (162979, 47231)\t0.12161833615006477\n",
      "  (162979, 103788)\t0.13830510254989897\n",
      "  (162979, 43151)\t0.0922201690943638\n",
      "  (162979, 69383)\t0.10561082092724194\n",
      "  (162979, 17962)\t0.0930068253672693\n",
      "  (162979, 74812)\t0.15343395605175814\n",
      "  (162979, 5191)\t0.11241623159748944\n",
      "  (162979, 5841)\t0.1755040283953335\n",
      "  (162979, 63947)\t0.11821826302011917\n",
      "  (162979, 95375)\t0.0832550249693682\n",
      "  (162979, 56603)\t0.10462706020729619\n",
      "  (162979, 65873)\t0.10545092368402072\n",
      "  (162979, 9779)\t0.08443245150365022\n",
      "  (162979, 105957)\t0.0807439792148072\n",
      "  (162979, 37266)\t0.06756510559574486\n",
      "  (162979, 104111)\t0.0835215522674346\n",
      "  (162979, 93828)\t0.13471479235478429\n",
      "  (162979, 95482)\t0.05546292741331128\n",
      "  (162979, 62481)\t0.03354737635251277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer Object using default parameters: use_idf=True, smooth_idf=True, sublinear_tf=False\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=False)\n",
    "\n",
    "# Fit to the corpus, then convert a collection of raw documents to a matrix of TF-IDF features.\n",
    "tf_idf_matrix = tfidf_vectorizer.fit_transform(twitter_data['clean_text'].values.astype('U'))\n",
    "\n",
    "print(f'The size of the tf_idf matrix for the texts = {tf_idf_matrix.get_shape()}')\n",
    "print(f'The sparse tf_idf matrix is as follows:')\n",
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Perform the tf-idf analysis on the column of the clean_text using HashingVectorizer and TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the count matrix for the texts = (162980, 1048576)\n",
      "The sparse count matrix is as follows:\n",
      "  (0, 160541)\t0.14907119849998599\n",
      "  (0, 168557)\t0.14907119849998599\n",
      "  (0, 180525)\t-0.4472135954999579\n",
      "  (0, 232512)\t0.14907119849998599\n",
      "  (0, 263274)\t0.14907119849998599\n",
      "  (0, 277794)\t-0.14907119849998599\n",
      "  (0, 286878)\t-0.29814239699997197\n",
      "  (0, 288398)\t0.14907119849998599\n",
      "  (0, 360502)\t0.29814239699997197\n",
      "  (0, 387101)\t-0.14907119849998599\n",
      "  (0, 433698)\t0.14907119849998599\n",
      "  (0, 434864)\t0.14907119849998599\n",
      "  (0, 449993)\t-0.14907119849998599\n",
      "  (0, 465141)\t-0.14907119849998599\n",
      "  (0, 482215)\t-0.14907119849998599\n",
      "  (0, 484920)\t-0.14907119849998599\n",
      "  (0, 490370)\t0.29814239699997197\n",
      "  (0, 522187)\t0.14907119849998599\n",
      "  (0, 614924)\t0.14907119849998599\n",
      "  (0, 646934)\t0.14907119849998599\n",
      "  (0, 747378)\t-0.14907119849998599\n",
      "  (0, 748718)\t0.14907119849998599\n",
      "  (0, 808196)\t-0.14907119849998599\n",
      "  (0, 839641)\t-0.14907119849998599\n",
      "  (0, 865698)\t0.14907119849998599\n",
      "  :\t:\n",
      "  (162979, 257965)\t0.16222142113076254\n",
      "  (162979, 286878)\t-0.16222142113076254\n",
      "  (162979, 338809)\t0.16222142113076254\n",
      "  (162979, 372702)\t0.16222142113076254\n",
      "  (162979, 408714)\t-0.16222142113076254\n",
      "  (162979, 413699)\t-0.16222142113076254\n",
      "  (162979, 433698)\t0.16222142113076254\n",
      "  (162979, 449993)\t-0.16222142113076254\n",
      "  (162979, 487855)\t-0.16222142113076254\n",
      "  (162979, 507870)\t-0.16222142113076254\n",
      "  (162979, 512176)\t0.16222142113076254\n",
      "  (162979, 528700)\t-0.16222142113076254\n",
      "  (162979, 642085)\t0.16222142113076254\n",
      "  (162979, 675997)\t0.16222142113076254\n",
      "  (162979, 707819)\t0.16222142113076254\n",
      "  (162979, 730607)\t-0.16222142113076254\n",
      "  (162979, 731192)\t0.3244428422615251\n",
      "  (162979, 800174)\t-0.16222142113076254\n",
      "  (162979, 814105)\t0.16222142113076254\n",
      "  (162979, 832412)\t0.16222142113076254\n",
      "  (162979, 865514)\t0.16222142113076254\n",
      "  (162979, 865966)\t0.16222142113076254\n",
      "  (162979, 975831)\t-0.16222142113076254\n",
      "  (162979, 994433)\t0.16222142113076254\n",
      "  (162979, 1031365)\t0.16222142113076254\n",
      "The size of the tf_idf matrix for the texts = (162980, 1048576)\n",
      "The sparse tf_idf matrix is as follows:\n",
      "  (0, 1011271)\t0.20372796396139078\n",
      "  (0, 926068)\t0.08143893743867205\n",
      "  (0, 913601)\t0.20197272603430663\n",
      "  (0, 865698)\t0.12597960273256398\n",
      "  (0, 839641)\t-0.26445858874355305\n",
      "  (0, 808196)\t-0.11614038289044132\n",
      "  (0, 748718)\t0.12555366048260833\n",
      "  (0, 747378)\t-0.2366176852585182\n",
      "  (0, 646934)\t0.10859027374399496\n",
      "  (0, 614924)\t0.15496390569273244\n",
      "  (0, 522187)\t0.18098737423653574\n",
      "  (0, 490370)\t0.23875611271519162\n",
      "  (0, 484920)\t-0.12029015749012335\n",
      "  (0, 482215)\t-0.14524788533773567\n",
      "  (0, 465141)\t-0.16616958502505294\n",
      "  (0, 449993)\t-0.1340069463492547\n",
      "  (0, 434864)\t0.20307710800247009\n",
      "  (0, 433698)\t0.03337110486864643\n",
      "  (0, 387101)\t-0.1889207337372532\n",
      "  (0, 360502)\t0.3104947539357193\n",
      "  (0, 288398)\t0.22829599512331\n",
      "  (0, 286878)\t-0.11034300552049593\n",
      "  (0, 277794)\t-0.25177893269287643\n",
      "  (0, 263274)\t0.2167508998548927\n",
      "  (0, 232512)\t0.11669246885631876\n",
      "  :\t:\n",
      "  (162979, 800174)\t-0.25797262773235685\n",
      "  (162979, 731192)\t0.3364434034047399\n",
      "  (162979, 730607)\t-0.1054511484111846\n",
      "  (162979, 707819)\t0.3407071263400122\n",
      "  (162979, 675997)\t0.0835217302607694\n",
      "  (162979, 642085)\t0.17550440241313411\n",
      "  (162979, 528700)\t-0.10561104599516391\n",
      "  (162979, 512176)\t0.08443263143820844\n",
      "  (162979, 507870)\t-0.2291129294490536\n",
      "  (162979, 487855)\t-0.08325520239470491\n",
      "  (162979, 449993)\t-0.13471507944637306\n",
      "  (162979, 433698)\t0.03354744784554934\n",
      "  (162979, 413699)\t-0.2720693593930217\n",
      "  (162979, 408714)\t-0.11821449781008107\n",
      "  (162979, 372702)\t0.09300702357473262\n",
      "  (162979, 338809)\t0.11240663186544564\n",
      "  (162979, 286878)\t-0.05546304561072428\n",
      "  (162979, 257965)\t0.18852715420744698\n",
      "  (162979, 213357)\t0.20296233321376997\n",
      "  (162979, 194734)\t0.3425161052926551\n",
      "  (162979, 189643)\t-0.06756524958419018\n",
      "  (162979, 181881)\t-0.17731413854092662\n",
      "  (162979, 176851)\t-0.2631914313500944\n",
      "  (162979, 77761)\t-0.12161407155894674\n",
      "  (162979, 60869)\t-0.12109410675052802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Create a Vectorizer Object using default parameters\n",
    "hash_vectorizer = HashingVectorizer()\n",
    "\n",
    "# Convert a collection of text documents to a matrix of token counts\n",
    "token_count_matrix=hash_vectorizer.fit_transform(twitter_data['clean_text'].values.astype('U'))\n",
    "print(f'The size of the count matrix for the texts = {token_count_matrix.get_shape()}')\n",
    "print(f'The sparse count matrix is as follows:')\n",
    "print(token_count_matrix)\n",
    "\n",
    "# Create a tf_idf object using default parameters\n",
    "tf_idf_transformer=TfidfTransformer(use_idf=True, smooth_idf=True, sublinear_tf=False) \n",
    "\n",
    "# Fit to the count matrix, then transform it to a normalized tf-idf representation\n",
    "tf_idf_matrix = tf_idf_transformer.fit_transform(token_count_matrix)\n",
    "\n",
    "print(f'The size of the tf_idf matrix for the texts = {tf_idf_matrix.get_shape()}')\n",
    "print(f'The sparse tf_idf matrix is as follows:')\n",
    "print(tf_idf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
